[
  {
    "objectID": "blog/posts/quarto-isolated-python-envs/index.html",
    "href": "blog/posts/quarto-isolated-python-envs/index.html",
    "title": "Isolated Python Environments for Quarto Blogs",
    "section": "",
    "text": "I recently moved this blog over to Quarto, mostly to make it easier to integrate relevant pieces of code into a few upcoming posts. Quarto files integrate markdown with executable code. The resulting documents are a bit like Jupyter notebooks in the sense that they interleave code and commentary. Unlike Jupyter notebooks, they can be edited in any text editor, which is an important feature for me as a long time Vim user. Quarto also has native support for blogging and better support for compilation to multiple formats. So far, I’ve had a good experience.\nThe one issue I’ve come across has to do with Quarto’s handling of Python environments. Quarto provides some documentation about using it alongside virtual environments, but the documentation seems to assume one virtual environment per project. For the purposes of a blog, I’d like one virtual environment per post; otherwise changing the environment can break rendering of an earlier post.\nHelpfully, Quarto documents support specifying a Jupyter kernel to use for rendering. Without a bit more structure, though, this option can lead to loose ends. Kernels dependencies can be altered iteratively, which can make them very difficult to reproduce. Even if they are created programmatically from environment specifications, manually recreating environments and kernels can be tedious.\nIn Quarto blogs, each post lives in its own directory For my purposes, I wanted it to be clear exactly what’s needed for each post’s code. I also wanted to be able to trivially reconstruct all the relevant kernels from their corresponding requirements.txt files. This is primarily because I believe in the principle of reproducibility and want others to be able to run the code easily. A secondary reason is that I edit this blog on two computers, and don’t want to have to worry about keeping environments up-to-date between them.\nThe result I landed on has two steps. The first is two include a requirements.txt file in the directory of each post that has executable python code. This puts the environment spec close to the relevant code, and makes it clear how to construct an environment that can run the code in that specific post. On its own, though, this leaves the problem of having to manually register and update kernels with Jupyter.\nThis leads to the second step, which is a bash script, copied below. The script searches for requirements.txt files in the posts directory, automatically creates a corresponding venv from each one, and registers that venv as a Jupyter kernel under the same name as the blog post’s directory. This reduces the setup for isolated python environments to running a single script. Now, we just need to specify the Jupyter kernel for the post, as linked above, in each post.\n# Install jupyter into the current enviornment if not already present\npip install jupyter\n\n# Create directory for virtualenvs\nmkdir \"${HOME}/venvs\"\n\n# For each post that has a requirements.txt file, create the corresponding kernel\nfind \"quarto-site/blog/posts\" -type f -name \"requirements.txt\" | while read requirements_file; do\n\n    # Get the name of the post corresponding to this requirements.txt file\n    dir_path=$(dirname \"${requirements_file}\")\n    dir_name=$(basename \"${dir_path}\")\n\n    # Create, activate, and install requirements for the venv\n    venv_path=\"${HOME}/venvs/${dir_name}\"\n    python -m venv \"${venv_path}\" --clear \n    source \"${venv_path}/bin/activate\"\n    pip install -r \"${requirements_file}\"\n    \n    # Register the venv as a Jupyter kernel\n    pip install ipykernel\n    python -m ipykernel install --user --name \"${dir_name}\" --display-name \"${dir_name}\"\n    \n    # Deactivate the venv\n    deactivate\ndone"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Noam Finkelstein",
    "section": "",
    "text": "Welcome to my website!\nI’ve spent the past decade working as a research scientist and engineer, primarily with clinical and biological data. Most recently, I was Head of Machine Learning at Delfina. In April, I’ll join the machine learning team at Flatiron Health.\nI hold a PhD in Computer Science and an ScM in Biostatistics from the Johns Hopkins University, a Bachelor’s degree in Politics, Philosophy and Economics from the University of Oxford, and an Associate’s degree from Deep Springs College.\nPlease feel free to get in touch."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Posts",
    "section": "",
    "text": "Isolated Python Environments for Quarto Blogs\n\n\n\n\n\n \n\n\n\n\n\n2024-02-13\n\n\n\n\n\n\nNo matching items"
  }
]