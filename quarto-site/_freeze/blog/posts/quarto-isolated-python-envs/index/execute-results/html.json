{
  "hash": "2b35b57f5ed203499e37c9b1a1f5e800",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Isolated Python Environments for Quarto Blogs\"\ndate: \"2024-02-13\"\ndate-modified: \"\"\ncategories: []\ndescription: \" \"\n---\n\nI recently moved this blog over to [Quarto](https://quarto.org/), mostly to make it easier to\nintegrate relevant pieces of code into a few upcoming posts. Quarto files incorporate markdown with\nexecutable code. The resulting documents are a bit like jupyter notebooks in the sense that they\ninterleave code and commentary. Unlike jupyter notebooks, they can be edited in any editor, which is\nan important feature to me. Quarto also has native support for blogging and better support for\ncompilation to multiple formats. So far, I've had a good experience of.\n\nThe one issue I've come across has to do with Quarto's handling of Python environments.\nQuarto provides some documentation about using it alongside \n[virtual environments](https://quarto.org/docs/projects/virtual-environments.html),\nbut the documentation seems to assume one virtual environment per project. For the purposes of a\nblog, I'd like one virtual environment per post; otherwise changing the environment can break\nrendering of an earlier post.\n\nHelpfully, Quarto documents support \n[specifying a jupyter kernel](https://quarto.org/docs/computations/python.html#kernel-selection)\nto use for rendering. Without a bit more structure, though, this option can lead to loose ends.\nKernels can be created iteratively, which can make them very difficult to reproduce on other\nmachines. Even if they are created programmatically from environment specifications, manually\nrecreating environments and kernels can be tedious.\n\nIn Quarto blogs, each post lives in \n[its own directory](https://quarto.org/docs/websites/website-blog.html#posts-directory)\nFor my purposes, I wanted it to be clear exactly what's needed for the post's code. I also wanted to\nbe able to trivially reconstruct all the relevant kernels from their corresponding\n`requirements.txt` files. This is primarily because I believe in the principle of reproducibility\nand want others to be able to run the code easily. A secondary reason is that I edit this blog on\ntwo computers, and don't want to have to worry about keeping environments up-to-date between them.\n\nThe result I landed on has two steps. The first is two include a `requirements.txt` file in the\ndirectory of each post that has executable python code. This puts the environment spec close to the\nrelevant code, and makes it clear how to construct an environment that can run the code in that\nspecific post.\n\nThe second step automates\n\n\n```{bash}\n# Install jupyter into the current enviornment if not already present\npip install jupyter\n\n# Create directory for virtualenvs\nmkdir \"${HOME}/venvs\"\n\n# For each post that has a requirements.txt file, create the corresponding kernel\nfind \"quarto-site/blog/posts\" -type f -name \"requirements.txt\" | while read requirements_file; do\n    # Get the directory of the found requirements.txt file\n    dir_path=$(dirname \"$requirements_file\")\n\n    # Extract the name of the directory where requirements.txt is located\n    dir_name=$(basename \"$dir_path\")\n\n    # Create a new directory for the venv with the name of the found directory\n    venv_path=\"${HOME}/venvs/${dir_name}\"\n    \n    # Create the virtual environment\n    python -m venv \"$venv_path\" --clear \n    \n    # Activate the virtual environment\n    source \"${venv_path}/bin/activate\"\n    \n    # Install requirements from the requirements.txt file\n    pip install -r \"$requirements_file\"\n\n    # register a corresponding kernel\n    pip install ipykernel\n    python -m ipykernel install --user --name \"${dir_name}\" --display-name \"${dir_name}\"\n    \n    # Deactivate the virtual environment\n    deactivate\ndone\n```\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}