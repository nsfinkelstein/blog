<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-02-07">

<title>Noam Finkelstein - Benchmarking Tasks for Document Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../icon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Noam Finkelstein</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#document-question-answering" id="toc-document-question-answering" class="nav-link active" data-scroll-target="#document-question-answering">Document Question Answering</a></li>
  <li><a href="#document-classification" id="toc-document-classification" class="nav-link" data-scroll-target="#document-classification">Document Classification</a></li>
  <li><a href="#document-layout-analysis" id="toc-document-layout-analysis" class="nav-link" data-scroll-target="#document-layout-analysis">Document Layout Analysis</a></li>
  <li><a href="#document-parsing" id="toc-document-parsing" class="nav-link" data-scroll-target="#document-parsing">Document Parsing</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Benchmarking Tasks for Document Analysis</h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 7, 2024</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">February 9, 2024</p>
    </div>
  </div>
    
  </div>
  


</header>


<p>This is the first post in a <a href="../../../blog/posts/pdf-series-intro">series</a> on document parsing. I’m starting with a review of the benchmarking tasks because I want to understand which problems the field is orienting itself around, and how they relate to the challenges of <a href="../../../blog/posts/pdf-series-intro#challenges-in-extracting-medical-data-from-pdfs">extracting data from medical Documents</a>.</p>
<p>The <a href="https://huggingface.co/blog/document-ai">Accelerating Document AI</a> post by Hugging Face covers some of the same ground. It was helpful context in writing this post and is worth a read.</p>
<p>I’ll update this post as I come across new relevant tasks.</p>
<section id="document-question-answering" class="level3">
<h3 class="anchored" data-anchor-id="document-question-answering">Document Question Answering</h3>
<p>The document question answer task takes a document (PDF, image, or text) and a natural language question about the document as inputs, and produces a natural language answer to that question as an output.</p>
<p>The <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD2.0</a> dataset is a dataset in which the documents are text (extracted from wikipedia articles), the questions are English, and each question is paired with one or more related substrings of the corresponding document, or a special token indicating that the question is not answered in the document. There are ~500 documents, with ~100,000 question-answer pairs, and an additional ~50,000 adversarial questions that seem like they might be answered in the document but are not.</p>
<p>These documents are not PDFs, but might be used to train the language part of a PDF parsing model. In the worst case, they can be automatically converted to either scanned or digital PDF format with simulated visual artifacts.</p>
<p>The <a href="https://www.docvqa.org/">DocVQA</a> collection has 4 distinct data sets. The <a href="https://www.docvqa.org/datasets/docvqa">DocVQA</a> dataset has ~12,000 images with ~50,000 questions. Answers are also text extracted from the given document image. There are also similar, smaller datasets for Infographics (rather than documents) and handwritten documents. The final dataset groups documents into a <a href="https://arxiv.org/abs/2104.14336">collection</a>, and any document in the collection can be used to answer the question.</p>
<p>The datasets can be downloaded <a href="https://rrc.cvc.uab.es/?ch=17&amp;com=downloads">here</a>, after creation of an account.</p>
<p>The related <a href="https://benchmarks.elsa-ai.eu/?ch=2&amp;com=downloads">PFL-DocVQA</a> dataset, which has ~1,000,000 question-answer pairs on ~110,000 documents in total. At the moment, it seems only ~250,000 are public, but the remainder should be published soon.</p>
<p>Both <a href="https://rrc.cvc.uab.es" class="uri">https://rrc.cvc.uab.es</a> and <a href="https://benchmarks.elsa-ai.eu" class="uri">https://benchmarks.elsa-ai.eu</a>, which host the DocVQA and PFL-DocVQA datasets respectively also have other interesting image-to-text datasets that might be useful for pre-training parts of a document model.</p>
<p>The <a href="https://rrc.cvc.uab.es/?ch=23&amp;com=introduction">DUDE</a> data set contains ~5,000 PDF documents, with ~20,000 question-answer pairs. Questions can be <em>extractive</em>, in which case the answer must appear in the document, as for the datasets above, or <em>abstractive</em>, in which case the answer does not appear in the document.</p>
<p>The <a href="https://github.com/adlnlp/pdfvqa#document-image-and-layout-structure-pickle-files">PDF-VQA</a> is also a visual question answer dataset. The authors point to the multi-page documents as the main differentiator from DocVQA. It contains ~12,000 single-page documents, and ~1,100 multi-page documents. It also contains ~140,000 question-answer pairs, and information about the logical and spatial relation of words in the document. The “relational graphs” that encode these relationships are described in section 3.2 of the the <a href="https://arxiv.org/pdf/2304.06447.pdf">accompanying paper</a>.</p>
</section>
<section id="document-classification" class="level3">
<h3 class="anchored" data-anchor-id="document-classification">Document Classification</h3>
<p>Document classification is what it sounds like.</p>
<p>The <a href="https://paperswithcode.com/dataset/rvl-cdip">RVL-CDIP</a> dataset contains ~400,000 images of documents, each of which is assigned to one of 16 classes. The leaderboard is <a href="https://paperswithcode.com/sota/document-image-classification-on-rvl-cdip">here</a>, and can be downloaded <a href="https://adamharley.com/rvl-cdip/">here</a>.</p>
<p>The <a href="https://www.kaggle.com/datasets/patrickaudriaz/tobacco3482jpg">Tobacco3482</a> dataset contains a ~3,492 images classified into 10 categories.</p>
</section>
<section id="document-layout-analysis" class="level3">
<h3 class="anchored" data-anchor-id="document-layout-analysis">Document Layout Analysis</h3>
<p>The layout analysis task aims to segment the documents into blocks, and classify each block. Common block labels are things like <em>text</em>, <em>title</em>, <em>figure</em>, <em>table</em>, etc.</p>
<p><a href="https://github.com/ibm-aur-nlp/PubLayNet#getting-data">PubLayNet</a> contains ~360,000 scientific papers drawn from PubMed. The dataset was constructed by “automatically matching XML representations and the contents” of the papers.</p>
</section>
<section id="document-parsing" class="level3">
<h3 class="anchored" data-anchor-id="document-parsing">Document Parsing</h3>
<p>The document parsing task aims to extract specific kinds of information from a document. In the case of forms, the goal is to extract key-value pairs, where each key is the name of a form-field, and the value is the user-entered text for that field. This is also sometimes called Key Information Extraction (KIE). Form and table parsing may be especially relevant to pulling information from medical records.</p>
<section id="forms-parsing" class="level4">
<h4 class="anchored" data-anchor-id="forms-parsing">Forms Parsing</h4>
<p>The Form Understanding from Noisy Scanned Documents (<a href="https://guillaumejaume.github.io/FUNSD/download/">FUNDS</a>) dataset has ~200 forms, with information about words and their locations, <em>semantic entities</em> — collections of related words —, and relations links between key-value pairs. <a href="https://guillaumejaume.github.io/FUNSD/description/">Here</a> is a nice summary-by-example of the data available on each form.</p>
<p>The related <a href="https://github.com/doc-analysis/XFUND">XFUND</a> dataset extends this idea to documents in other languages. The dataset repository doesn’t have much information, but it’s described in the <a href="https://arxiv.org/abs/2104.08836v3">LayoutXLM</a> paper. XFUND contains ~1,400 annotated forms, at ~200 per language. The dataset contains standard OCR data (i.e.&nbsp;words with bounding boxes), as well as semantically significant sets of words, each of which is called a <em>semantic entity</em>. It also contains annotated key-value pairs; a major goal is identifying the value associated with a given key.</p>
</section>
<section id="table-parsing" class="level4">
<h4 class="anchored" data-anchor-id="table-parsing">Table parsing</h4>
<p>The <a href="https://huggingface.co/datasets/bsmock/pubtables-1m">PubTables-1M</a> dataset contains ~575,000 pages, with a total of ~950,000 fully annotated tables. <a href="https://user-images.githubusercontent.com/10793386/139559159-cd23c972-8731-48ed-91df-f3f27e9f4d79.jpg">Table annotations</a> include column headers and <em>projected row headers</em>, which are used to subdivide the table into vertical sections (see the linked image for an example). The dataset can also be used to learn to identify tables in documents.</p>
<p>The <a href="https://developer.ibm.com/exchanges/data/all/fintabnet/">FinTabNet</a> dataset “contains complex tables from the annual reports of S&amp;P 500 companies with detailed table structure annotations”. It has ~90,000 pages with ~110,000 tables. The annotations here seem to just indicate a bounding box for each <em>table</em>, and a bounding box for each <em>cell</em> in the table. See the bottom of <a href="https://dataplatform.cloud.ibm.com/analytics/notebooks/v2/f57cf3f6-e972-48ff-ab7b-3771ba7b9683/view?access_token=317644327d84f5d75b4782f97499146c78d029651a7c7ace050f4a7656033c30">this notebook</a> for examples. There is also an improved version called <a href="https://huggingface.co/datasets/bsmock/FinTabNet.c">FinTabNet.c</a> available on hugging face.</p>
<p>On first look, it doesn’t seem that either dataset includes a class for the kinds of notes that often appear in lab test reports (<a href="https://www.researchgate.net/profile/John-Flach/publication/267494297/figure/fig1/AS:392037380706311@1470480403318/An-example-of-a-typical-format-used-to-report-results-of-blood-analysis-to-the-physician.png">example 1</a>, <a href="https://i.pinimg.com/736x/8e/a6/ef/8ea6efe0d12a1a580e8d1b3390a3e066.jpg">example 2</a>). These kinds of notes often disrupt table recognition, as the same column headers apply above and below the note. I’ve had trouble in the past where table identifiers either considered the parts of a table separated by a note to be distinct tables, or else only recognized the part of the table that precedes the note, as the remaining parts do not have identifiable column headers.</p>
<p>Because the FinTabNet does not contain semantic information about table structure, models trained on it might be better able to recognize the notes as distinct cells; this will be interesting to explore.</p>
<p>There is also the <a href="https://huggingface.co/datasets/bsmock/ICDAR-2013-Table-Competition-Corrected">ICDAR2013 table competition dataset</a>, which is available in corrected form on hugging face. The dataset is described in <a href="https://corpora.tika.apache.org/base/docs/bug_trackers/tabula/tabula-java-LINK-49-1.pdf">this paper</a>. It contains table location and structure information.</p>
<p>A summary of these three datasets, as well as interesting commenatry about using them together, can be found <a href="https://arxiv.org/pdf/2303.00716.pdf">here</a>.</p>
</section>
<section id="receipts-parsing" class="level4">
<h4 class="anchored" data-anchor-id="receipts-parsing">Receipts Parsing</h4>
<p>The <a href="https://rrc.cvc.uab.es/?ch=13&amp;com=introduction">SROIE dataset</a> has ~1,000 receipt images. Each receipt is annotated with standard word / bounding box information, as well as a number of key-value pairs (the example keys given are <em>company</em>, <em>date</em>, <em>address</em>, and <em>total</em>).</p>
<p>The <a href="https://github.com/clovaai/cord">CORD</a> dataset has ~1,0000 receipts. Each receipt is annotated with word / bounding box information, as well as line-level and receipt-level classifications.</p>
</section>
<section id="datasets-in-other-languages" class="level4">
<h4 class="anchored" data-anchor-id="datasets-in-other-languages">Datasets in other languages</h4>
<p>I’ll focus on English datasets for now, both because I can read English and because the documents I’m interested in working with are in English. There are interesting datasets in other languages, especially in Chinese. In particular, the <a href="https://rrc.cvc.uab.es/?ch=21">HUSTL-CELL</a> dataset looks relevant to key information extraction, and is primarily in Chinese.</p>
</section>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>This post is meant to provide an overview of the kinds of tasks that are currently used to evaluate methods for Document AI. The corresponding datasets can be used for training or fine-tuning as well.</p>
<p>My overall impression is that there is low availability of large, high-quality annotated datasets, especially for the <a href="#document-parsing">parsing</a>-based tasks. This seems to be a bottleneck for training, though perhaps less so for evaluation.</p>
<p>In the next post in the series, we’ll look at unlabeled datasets that can be used for self-supervised pre-training. I will be especially interested in methods for generating synthetic labeled data. For medical document information extraction, it may be relevant to see if plausible documents of varied structures can be created using synthetic FHIR data from <a href="https://github.com/synthetichealth/synthea">Synthea</a>.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>