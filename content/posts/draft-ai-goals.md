+++
title = "Can artificial intelligences have goals?"
draft = true
+++

In a recent interview, [Kelsey Piper](https://www.vox.com/authors/kelsey-piper) of Vox made the
following comment about goals:

> we don’t know if the A.I.s have goals. And some people will say they clearly don’t have goals
> because how would something like that have goals? And I’m just kind of like, I don’t know.
> Evolution was just selecting repeatedly on ability to have babies, and here we are. We have goals.
> Why does that process get you things that have goals? I don’t know. They just showed up along the
> way. Large language models are just selecting repeatedly on token prediction and then
> reinforcement. Does that have goals? I think if anybody tells you yes or no, they are overstating
> what we know and what we can know.

Thinking about whether artificial intelligences can develop goals in the context of evolution is
interesting.

I'm not an expert in evolution, but I do think it's easy to see why having goals is useful from an
evolutionary perspective. The implicit objective that evolutionary pressures respond to is survival
to reproduction. Survival in the real world is a difficult, open-ended problem. Creatures that are
able to break that problem down into smaller pieces, each of which eventually contribute to the
larger objective, and each of which they feel an inclination to achieve, are more likely to survive.
So it doesn't seem mysterious that the process of evolution produces being with goals. Those goals
look different across species, but we all have them to some degree, I think generally the complexity
of the goal increases with the size of the species.

Does AI, trained on next-token prediction, have anything remotely like that? What if we add
reinforcement of different kinds?

Another important point - neural networks don't have a sense of "time". When they're given an input,
that triggers one or more discrete, predetermined series of computations. When they're not given an
input, they're not thinking, or analyzing the world, or evaluating how they're measuring up to their
goals. It's a bit unclear what it would mean to have goals in this context. Where would the goals
get stored?? Not in the weights of the network. Maybe, in the very short term, they could somehow be
represented in the state vectors of the network.
